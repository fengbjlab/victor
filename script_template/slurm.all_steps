#!/bin/bash
#SBATCH --time=72:00:00
#SBATCH --output=%x.run_%a.stdout
#SBATCH --error=%x.run_%a.stderr

# About:
# This script submits a job to a computer cluster to do quality control, annotation, and PERCH analysis starting from a raw VCF file.
# This file is more readable if the text editor or terminal width is at least 160 characters.
# Comments starting with ### are suggested manual operations.

# Quick usage (if you have installed PROVEAN):
# 1. Add /path/to/VICTOR to your PATH.
# 2. Copy this scrip to a working directory where you have write permissions. Optionally, put a par.txt in the same directory. See Manual about par.txt.
# 3. Optionally, add #SBATCH options above. Such as --account --partition --mail-user --mail-type.
# 4. Set parameters including "Set PATH", "What to do", "Main Parameters", "Other Programs", "PERCH files", "PERCH Parameters", and "PERCH sub-analysis".
# 5. Submit a job to a computer cluster by "victor.sbatch --array=1 slurm.all_steps".
# 6. Check errors and warnings (See "Explanations" below). Inspect results files (see "What to do" below).

# More complicated usage (if you have NOT installed PROVEAN, or you are not sure about the quality control parameters):
# 1. Add /path/to/VICTOR to your PATH.
# 2. Copy this scrip to a working directory where you have write permissions. Optionally, put a par.txt in the same directory. See Manual about par.txt.
# 3. Optionally, add #SBATCH options above. Such as --account --partition --mail-user --mail-type.
# 4. Set parameters including "Set PATH", "Main Parameters", "Other Programs", "PERCH files", "PERCH Parameters", and "PERCH sub-analysis".
# 5. Change the "What to do" ("yes" to STEP_0 to SPL_QC, "no" to anything after), submit a job by "victor.sbatch --array=1 slurm.all_steps".
# 6. Review the files $OUT.sample_rm and $OUT.1st.sample_qc. Modify the "Sample-wise QC Filters" cutoff values or other parameters if necessary.
# 7. If you did not install PROVEAN, submit $OUT.for_PROV to provean.jcvi.org, download xxx.result.one.tsv, then set PVN=xxx.result.one.tsv.
# 8. Change the "What to do" ("yes" to SPL_QC and after, "no" to STEP_0 and STEP_1), submit a job by "victor.sbatch --array=2 slurm.all_steps".
# 9. Check errors and warnings (See "Explanations" below). Inspect results files (see "What to do" below).

# Usage without a job scheduler (i.e., directly execute this slurm script):
#   chmod +x slurm.all_steps
#   export SLURM_ARRAY_TASK_ID=1
#   SLURM_JOB_NAME=slurm.all_steps ./slurm.all_steps 1>slurm.all_steps.run_$SLURM_ARRAY_TASK_ID.stdout 2>slurm.all_steps.run_$SLURM_ARRAY_TASK_ID.stderr
#   unset SLURM_ARRAY_TASK_ID
# Increase SLURM_ARRAY_TASK_ID by 1 in each subsequent execution.

# Explanations:
# The --array option of victor.sbatch assigns a value to SLURM_ARRAY_TASK_ID. Remember to add 1 to the --array argument each time you submit a job.
# You can change the name of this file.
# You can put multiple scripts in the same working directory and submit jobs simultaneously, but make sure $OUT in the "Main Parameters" are different.

# Commands to check errors after running a job (please replace # with the SLURM_ARRAY_TASK_ID):
#   ERROR_TEXT="error\|throwing\|exception\|what()\|Killed\|slurmstepd\|NODE_FAIL\|Broken pipe\|too many arguments\|segmentation\|reindex\|Aborted"
#   grep -i "$ERROR_TEXT" slurm.all_steps.run_#.stderr
# Commands to check warnings:
#   grep -i warning slurm.all_steps.run_#.stderr
# Commands to see what have been done:
#   grep -i completed slurm.all_steps.run_#.stderr

# Tips for gene panel sequencing. 
# Some sample-wise quality measures in gene panel data do not have the same distribution as those in the genome-wide scale. 
# The default cutoff values in this script are designed for WES/WGS, so you may want to change the cutoff values for a gene-panel sequencing experiment.
# However, the appropriate cutoff values may vary from panel to panel. The best way to solve it is to run an analysis without step_2, step_3, step_4,
# find the appropriate cutoff for Het/Hom and Ti/Tv, set the parameters, and run analysis starting from SPL_QC (STEP_0,STEP_1 are no, others are yes).
# Distribution of Het/Hom, Ti/Tv and other QC metrics can be obtained from $OUT.1st.sample_qc.

# Tips for non-European populations.
# You may want to change the cutoff values for Het/Hom ratio if your study population is not European. The procedures are in the previous paragraph.

# ----------------------------------------------------------------- parameters_section_1/2 -----------------------------------------------------------------

# Set PATH.
# If you have not added VICTOR to your PATH, un-comment "export PATH=/path/to/VICTOR:$PATH" and replace /path/to; otherwise, no need to do anything.
# If you installed pkg but have not add it to your PATH, un-comment "export PATH=/path/to/pkg" and replace /path/to.
# If you use module, write "ml" commands below.
#   export PATH=/path/to/VICTOR:$PATH
#   export PATH=/path/to/pkg:$PATH
#   export PATH=/path/to/pkg/PROVEAN/bin:$PATH

# Check whether PATH is set correctly.
VICTOR_PATH=`which vAnnGene | sed 's;/vAnnGene$;;'`
GENOME_NAME=`vAnnGene -h | grep genome | sed 's;/};;' | sed 's;.*/;;'`
if [ "$SLURM_JOB_NAME" == "" ]; then SLURM_JOB_NAME=`basename "$0"`; fi
if [ "$VICTOR_PATH" == "" ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: path to VICTOR is not set'; exit 1; fi
if [ "$GENOME_NAME" == "" ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: genome assembly is not set'; exit 1; fi

# What to do. Select successive major steps (0,1,2,3,4) below. Minor steps (a,b,c,d,e) are optional. Value is either yes or no.
STEP_0=yes # Step 0  : Split a VCF by chromosome.
STEP_1=yes # Step 1  : Variant-wise quality control and basic annotations (MaxAF, BayesDel, func consequence)
SPL_QC=yes # Step 1.a: Sample-wise quality control
SEX_QC=yes # Step 1.b: Check whether genetic sex match with reported sex. Requires SPL_QC.
PED_QC=yes # Step 1.c: Calculate sample relatedness (for pedigree structure quality control)
REL_QC=yes # Step 1.d: Calculate sample relatedness (for cryptic relatedness quality control)
SPL_PC=no  # Step 1.e: Principle component analysis (for population stratification quality control)
IMPUTE=no  # Step 1.f: Prepare a file for imputation, do imputation yourself, then merge VCFs.
STEP_2=yes # Step 2  : More annotations (BayesDel, functional consequence)
STEP2B=yes # Step 2.b: PERCH report incidental findings.                                                       Requires STEP_0. Result files: $OUT.incidental.*
STEP_3=yes # Step 3  : PERCH analysis (gene prioritization, variant prioritization, VUS classification, etc.). Requires STEP_2. Result files: $OUT.results_*
STEP4A=yes # Step 4.a: PERCH analysis (pathway/gene-set).                                                      Requires STEP_3. Result files: $OUT.gsa.*
STEP4B=no  # Step 4.b: PERCH analysis after removing samples carrying variants in known high-penetrance genes. Requires STEP2B. Result files: $OUT.rmHPG.*
STEP4C=no  # Step 4.c: PERCH analysis with ExAC nonTCGA. Not recommended.                                      Requires STEP_2. Result files: $OUT.ExAC.*

# Main Parameters. Do not set XXX=yes or XXX=no below; values should be filenames or program options. Leave it blank if you don't know what to do.
# If an input file is not in the working directory, use full path or relative path. Remember to quote if the argument contains a space.
# Basic parameters
export CHF=$VICTOR_PATH/script_template/chr_noM # mandatory. Chromosomes to be analyzed.
export OUT=VICTOR                               # mandatory. output prefix.
export VCF=../files/geno.recal.vcf.gz           # mandatory. raw VCF containing genotypes for all #CHROM and all samples; should contain VQSLOD scores.
export SPL=../files/samples.txt                 # mandatory, Sample File. ID should not contain equals sign (=), semicolon (;) or comma (,). See "Note F".
export PED=../files/pedigrees.txt               # optional. Pedigree File. See "Note A" and "Note F" below.
export GBA=                                     # optional. Guilt-By-Association score file (two columns: gene_symbol score) created by gnGBA.
export AVF=                                     # optional. Array VCF File. See "Note B" below.
export RMS=                                     # optional. Parameters for removing samples (e.g., RMS="--rm-ind+=File_of_SeqIDs_To_Remove").
export PRL=                                     # optional. Number of jobs in parallel. If your computer has <24 cores, set PRL to a small number.
# For step 1
export AN1=                                     # optional. Parameters for additional annotations by vAnnDel. See "Note C" below.
export AN2=                                     # optional. Parameters for additional annotations by vAnnDel. See "Note C" below.
export AN3=                                     # optional. Parameters for additional annotations by vAnnDel. See "Note C" below.
export AN4=                                     # optional. Parameters for additional annotations by vAnnDel. See "Note C" below.
export AN5=                                     # optional. Parameters for additional annotations by vAnnDel. See "Note C" below.
export QC1=                                     # optional. Parameters for quality control by vQC on each chromosome. See "Note D" below.
export QCJ=                                     # optional. Parameters for quality control by vQC --join-sample-qc to join results from each chromosome.
export VAM=                                     # optional. Parameters for MaxAF annotation by vAnnDel.
export KEEP_REL=                                # optional. If $AAA has --weight, set KEEP_REL=yes to keep related individuals except duplicates / mz-twins.
export KEEP_COMMON=0.2                          # optional. Keep non-functional variants that have a MaxAF>$KEEP_COMMON for PED_QC/REL_QC but not STEP3/4.
export VAR_MISS=0.01                            # Exclude variants with a high missing rate. VAR_MISS=1 to disable this filter.
export SPL_MISS=0.005                           # For sample-wise QC, missing rate cutoff.   SPL_MISS=1 to disable this filter.
export HeHo_Cut=4                               # For sample-wise QC, Het/Hom ratio cutoff.  HeHo_Cut=0 to disable this filter.
export TiTv_Cut=2.5                             # For sample-wise QC, Ti/Tv ratio cutoff.    TiTv_Cut=0 to disable this filter.
export Conc_Cut=99                              # For sample-wise QC, concordance cutoff.    Conc_Cut=0 to disable this filter.
export AvGQ_Cut=55                              # For sample-wise QC, mean GQ cutoff.        AvGQ_Cut=0 to disable this filter.
export AvDP_Cut=20                              # For sample-wise QC, mean DP cutoff.        AvDP_Cut=0 to disable this filter.
export IM2=                                     # optional. Prefix of VCFs created by slurm.impute2mrg. Fullnames are $IM2.chr$CHR.mrg.qc.vcf.gz.
export USE_TABIX=                               # optional. Set USE_TABIX=yes if $VCF is small.
# For step 2
export ADF=                                     # optional. Parameters for vAnnDomain --add (do nothing if empty).
export VAG=                                     # optional. Parameters for gene annotation by vAnnGene.
export DEL=                                     # optional. Parameters for BayesDel calculation by vDEL.
export PVN=                                     # optional. PROVEAN score file for new indels. See "Compute PROVEAN" below.
# For step 2 phasing
export PHA=no_phasing                           # optional, how to phase the genotypes (ShapeIt or BEAGLE; anything else means "no phasing")
export MAP=/path/to/genetic_map                 # optional, but mandatory if PHA=ShapeIt. Filenames are $MAP/genetic_map_chr$CHR.txt.
export BGL="/path/to/beagle.jar ped=$PED"       # optional, but mandatory if PHA=BEAGLE.
export QC2="$QC1"                               # optional, Parameters for quality control by vQC after phasing. Normally it should be the same as QC1.
# For step 3
export AAA=                                     # optional. Parameters for association analysis by vAAA.(E.g.: --filt-xxx --logistic --linear --weight --sv)
export SEG=                                     # optional. Parameters for linkage analysis by vSEG.    (E.g.: --filt-xxx)
export FIN=                                     # optional. Parameters for combining results by vFIN.   (E.g.: --neg-biol) Do not set --biol here; use $GBA.
# For step 4.a
export GSA=                                     # optional. Parameters for variant selection by vGrp in gene set analysis
# For step 4.b
export HPG=                                     # optional. High-Penetrance Genes for STEP4B. Gene symbols separated by a comma. Default is panel_incidental.
# For step 4.c
export COV=                                     # optional. Prefix of coverage files for Step 4.c. See "Note E" below.
export EFP=ExAC1/noTCGA                         # optional. Prefix of ExAC files for Step 4.c.
export AWX=                                     # optional. Parameters for rare-variant association analysis by vAAA comparing cases to ExAC in Step 4.c.
# For future use
export PMT=                                     # For future use.
# Note A: If you have a pedigree file for quality control but not for analysis, set SEG=--do-nothing above.
# Note B: If you have both sequence data and dense genotyping array data for the same samples, this option will merge the two data for one analysis.
#         You need to first run the step 0-1.x on the array data to create $AVF, then set the AVF and run steps 0-3 on the sequence data.
#         The sample IDs in $AVF should be the same as those in $VCF, though it could contain more or less samples with different orders.
# Note C: Annotation File is a tabix-indexed tab-delimited file with at least 5 columns: #CHROM POS REF ALT Ann1 Ann2 ..
#         Ann1, Ann2, .. can be any text except MaxAF. If they are allele frequencies, please also set --af=Ann1,Ann2,.. in the par.txt.
#         If your allele frequency data came from a small study (a few thousands samples), it's better to exclude variants with <5 minor allele counts.
#         Do not use your controls to calculate allele frequency in making this file! Otherwise it will increase the type I error rate.
# Note D: A commonly used option is QC1="--cohort=/path/to/cohort_file" if your samples were target-enriched or sequenced by different reagents or platforms.
#         Do not use the --filt-miss-rate option; instead, set that parameter by VAR_MISS.
# Note E: Coverage files list the number of samples with at least 20x coverage at each basepair position. Each file is for one chromosome. 
#         These files will be used by Step 4.c STEP4C. So if STEP4C=yes, the variables $COV must be set. Names of files are $COV.chr*.cov.gz.
#         The files have 3 columns: Chromosome 1-based-position Number_of_Samples_covered_by_20x. They have no header lines.
#         Do not include the position that <90% of the samples were covered by 20x.
# Note F: If your Sample File and Pedigree File for QC are different from those for association and linkage analysis, set the files for QC to $SPL and $SEG;
#         then, set the files for analysis to $SPL_FILE and $PED_FILE below.

# Other Programs. Ask your computer manager about how to use GNU parallel, tabix, PLINK 1.9, KING, and GATK.
# If GNU parallel or GATK complains about not being able to write in /tmp, un-comment the next line and add -Djava.io.tmpdir=./ to $GATK.
# export TMPDIR=./
# module load parallel
# module load tabix
export GATK="java -Xmx2g -jar /path/to/gatk.jar -R /path/to/reference_genome.fasta"
export PLINK19="plink_1.9 --allow-no-sex"
export KING=king

# -------------------------------------------------------------------- end_of_section1/2 --------------------------------------------------------------------
  
# Check parameters
if [ "$OUT" == "" ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: OUT in the "Main Parameters" cannot be empty'; exit 1; fi
if [ "$SPL" == "" ] && [[ "$QC1" != *"--do-nothing"* ]]; then echo >&2 $SLURM_JOB_NAME': !!! Error: SPL in "Main Parameters" cannot be empty'; exit 1; fi
if [ "$SPL" != "" ] && [ ! -s "$SPL" ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: '$SPL' not exist or empty.'; exit 1; fi
if [ "$PED" != "" ] && [ ! -s "$PED" ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: '$PED' not exist or empty.'; exit 1; fi
if [ "$CHF" != "" ] && [ ! -s "$CHF" ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: '$CHF' not exist or empty.'; exit 1; fi
if [ "$PVN" != "" ] && [ ! -s "$PVN" ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: '$PVN' not exist or empty.'; exit 1; fi
if [ "$GBA" != "" ] && [ ! -s "$GBA" ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: '$GBA' not exist or empty.'; exit 1; fi
if [ "$AVF" != "" ] && [ ! -f "$AVF"     ];  then echo >&2 $SLURM_JOB_NAME': !!! Error: '$AVF' is not a file or does not exist'; exit 1; fi
if [ "$AVF" != "" ] && [ ! -f "$AVF.tbi" ];  then echo >&2 $SLURM_JOB_NAME': !!! Error: '$AVF' is not tabix-indexed'; exit 1; fi
if [ "$STEP4C" == yes ] && [ "$COV" == "" ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: COV is not set but STEP4C is yes'; exit 1; fi
if [ "$STEP4C" == yes ] && [ "$EFP" == "" ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: EFP is not set but STEP4C is yes'; exit 1; fi
if [ "$VAR_MISS" != "" ]; then export QC1="--filt-miss-rate=$VAR_MISS $QC1"; fi
if [ "$SPL_MISS" == "" ]; then export SPL_MISS=0.005; fi
if [ "$PHA" == ShapeIt ] && [ "$MAP" == "" ]; then >&2 echo $SLURM_JOB_NAME': !!! Error: MAP not set.'; exit 1; fi
if [ "$PHA" == BEAGLE  ] && [ "$BGL" == "" ]; then >&2 echo $SLURM_JOB_NAME': !!! Error: BGL not set.'; exit 1; fi
if [ `head -1 $SPL|tr '\t' '\n'|grep -i ^pop$|wc -l` -eq 1 ] && [ "$SPL_PC" == yes ]; then >&2 echo $SLURM_JOB_NAME': !!! Error: SPL has pop'; exit 1; fi
if   [[ "`uname | tr '[:upper:]' '[:lower:]'`" == linux  ]]; then
  export ZCAT=zcat
  export NCPU=`nproc`
  export MEM_TOTAL=`free -g | grep Mem | awk '{ print $7 }'`
elif [[ "`uname | tr '[:upper:]' '[:lower:]'`" == darwin ]]; then
  export ZCAT=gzcat
  export NCPU=`sysctl -n hw.ncpu`
  FREE_BLOCKS=$(vm_stat | grep free | awk '{ print $3 }' | sed 's/\.//')
  INACTIVE_BLOCKS=$(vm_stat | grep inactive | awk '{ print $3 }' | sed 's/\.//')
  SPECULATIVE_BLOCKS=$(vm_stat | grep speculative | awk '{ print $3 }' | sed 's/\.//')
  FREE=$((($FREE_BLOCKS+SPECULATIVE_BLOCKS)*4096/1048576/1024))
  INACTIVE=$(($INACTIVE_BLOCKS*4096/1048576/1024))
  export MEM_TOTAL=$((($FREE+$INACTIVE)))
else
  echo >&2 $SLURM_JOB_NAME': !!! Error: unknown OS.'
  exit 1
fi
export NUM_CHR=`grep -v ^# $CHF | wc -l`
export QC_THREADS=$((NCPU/NUM_CHR))
if [ "$QC_THREADS" -lt 1 ]; then export QC_THREADS=1; fi
if [ "$NCPU" -lt "$NUM_CHR" ] && [ "$PRL" == "" ]; then export PRL=$NCPU; fi
if [ "$PRL" != "" ]; then export PRL_OPT="-j $PRL"; fi
>&2 echo "$SLURM_JOB_NAME: NCPU=$NCPU"
>&2 echo "$SLURM_JOB_NAME: MEM_TOTAL=$MEM_TOTAL"
>&2 echo "$SLURM_JOB_NAME: QC_THREADS=$QC_THREADS"
>&2 echo "$SLURM_JOB_NAME: PRL_OPT=$PRL_OPT"

# Check programs
command -v parallel >/dev/null 2>&1 || { echo >&2 $SLURM_JOB_NAME': !!! Error: parallel not found.'; exit 1; }
command -v tabix    >/dev/null 2>&1 || { echo >&2 $SLURM_JOB_NAME': !!! Error: tabix not found.'; exit 1; }
command -v bgzip    >/dev/null 2>&1 || { echo >&2 $SLURM_JOB_NAME': !!! Error: bgzip not found.'; exit 1; }

# Begin of job
if [ "$SLURM_ARRAY_TASK_ID" == "" ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: SLURM_ARRAY_TASK_ID not defined'; exit 1; fi
JOB_DIR=`pwd`
JOB_LOG=$JOB_DIR/$SLURM_JOB_NAME.run_${SLURM_ARRAY_TASK_ID}
if [ -s $JOB_DIR/$SLURM_JOB_NAME ]; then cp $JOB_DIR/$SLURM_JOB_NAME $JOB_LOG.script; fi
if [ -s $JOB_DIR/$SLURM_JOB_NAME.account ]; then cp $JOB_DIR/$SLURM_JOB_NAME.account $JOB_LOG.account; fi
vQC --version --no-web 2> $JOB_LOG.version
echo "# $(date)"                                             > $JOB_LOG.start
echo "# SLURM_JOBID = $SLURM_JOBID"                         >> $JOB_LOG.start
echo "# SLURM_NODELIST = $SLURM_NODELIST"                   >> $JOB_LOG.start
echo "# To abort this job: cat $JOB_LOG.start | bash"       >> $JOB_LOG.start
echo "scancel $SLURM_JOBID"                                 >> $JOB_LOG.start
if [ -s par.txt ]; then cp par.txt $JOB_LOG.par; fi
export ERROR_TEXT="error\|throwing\|exception\|what()\|Killed\|slurmstepd\|NODE_FAIL\|Broken pipe\|too many arguments\|segmentation\|reindex\|Aborted"

OS=`uname | tr '[:upper:]' '[:lower:]'`
if   [[ "$OS" == 'linux' ]]; then  PRFX=`mktemp --tmpdir=. XXXXXXXXXX` && PRFX=${PRFX:2}
elif [[ "$OS" == 'darwin' ]]; then PRFX=`mktemp            XXXXXXXXXX`
else echo >&2 $SLURM_JOB_NAME': !!! Error: unknown OS '$OS; exit 1; fi
export STDERR_MUTEX=$PRFX

# Check input files
if [ -s "$PED" ]; then
  pedpro --prefix $JOB_LOG.ped --ped $PED
  if [ `grep "recognized:$" $JOB_LOG.ped.log | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: '$PED' has no header row'; exit 1; fi
  if [ `grep "Found circles" $JOB_LOG.ped.log | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: '$PED' has marriage loops'; exit 1; fi
  if [ `grep "Found loops" $JOB_LOG.ped.log | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: '$PED' has consanguinity loops'; exit 1; fi
  if [ `grep "Found multiple clusters" $JOB_LOG.ped.log | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: '$PED' has isolates'; exit 1; fi
  if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr|wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! '$PED has errors. Check $JOB_LOG.ped.log; exit 1; fi
  if [ `grep -i error $JOB_LOG.ped.log | grep -v ' 0 error' | wc -l` -gt 0 ]; then
    echo >&2 $SLURM_JOB_NAME': !!! '$PED has errors. Please check $JOB_LOG.ped.log
    exit 1
  fi
  if [ `grep -i warning $JOB_LOG.ped.log | grep -v ' 0 warning' | wc -l` -gt 0 ]; then
    echo >&2 $SLURM_JOB_NAME': !!! '$PED has warnings. Please check $JOB_LOG.ped.log
    exit 1
  fi
fi

if [ "$AVF" != "" ] && [ "$VCF" != "" ] && [[ "$QC1" != *--rep* ]]; then
  if [ "$VCF" != "" ] && [ ! -f "$VCF"     ];  then echo >&2 $SLURM_JOB_NAME': !!! Error: '$VCF' is not a file or does not exist'; exit 1; fi
  if [ "$VCF" != "" ] && [ ! -f "$VCF.tbi" ];  then echo >&2 $SLURM_JOB_NAME': !!! Error: '$VCF' is not tabix-indexed'; exit 1; fi
  $ZCAT $VCF | head -2000 | grep ^#C | cut -f 10- | tr '\t' '\n' | sort > $PRFX.spl1
  $ZCAT $AVF | head -2000 | grep ^#C | cut -f 10- | tr '\t' '\n' | sort > $PRFX.spl2
  join $PRFX.spl1 $PRFX.spl2 | sed 's/^\(.*\)$/\1\t\1/' > $PRFX.overlap
  export QC1="--rep=$PRFX.overlap,$AVF $QC1"
fi

# Step 0: split a VCF by chromosome and split multi-allelic variants
if [ "$STEP_0" == yes ]; then
  echo >&2 $SLURM_JOB_NAME': begin to split a VCF by chromosome and split multi-allelic variants '$(date)
  if [ "$VCF" == "" ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: VCF in the "Main Parameters" cannot be empty'; exit 1; fi
  if [ "$VCF" != "" ] && [ ! -f "$VCF"     ];  then echo >&2 $SLURM_JOB_NAME': !!! Error: '$VCF' is not a file or does not exist'; exit 1; fi
  if [ "$VCF" != "" ] && [ ! -f "$VCF.tbi" ];  then echo >&2 $SLURM_JOB_NAME': !!! Error: '$VCF' is not tabix-indexed'; exit 1; fi
  my_func() { tabix $VCF $1:1-300000000 -h | bgzip -c > $OUT.chr$1.vcf.gz;
              tabix -f -p vcf $OUT.chr$1.vcf.gz; }
  export -f my_func
  parallel $PRL_OPT -a $CHF my_func
  TABIXERROR="the index file either does not exist or is older than the vcf file. Please reindex."
  if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at STEP_0'; exit 1; fi
  if [ `grep -i "$TABIXERROR" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at STEP_0'; exit 1; fi
  echo >&2 $SLURM_JOB_NAME': STEP_0 completed '$(date)
fi

# Step 1: variant-wise quality control and basic annotations
if [ "$STEP_1" == yes ]; then
  echo >&2 $SLURM_JOB_NAME': begin to do variant-wise quality control and basic annotations '$(date)
  my_func() { INP=$OUT.chr$1.vcf.gz SPL=$SPL PED=$PED \
              VAM=$VAM AN1=$AN1 AN2=$AN2 AN3=$AN3 AN4=$AN4 AN5=$AN5 KEEP_COMMON=$KEEP_COMMON \
              QC1="$RMS --sample-qc=$OUT.chr$1.sample_qc --out-vqs=$OUT.chr$1.vqslod --nt=$QC_THREADS $QC1" \
              STEP1_ONLY=yes USE_TABIX=$USE_TABIX victor_by_chr; }
  export -f my_func
  parallel $PRL_OPT -a $CHF my_func
  cat $OUT.chr*.vqslod   > $OUT.vqslod   && rm -f $OUT.chr*.vqslod
  cat $OUT.chr*.for_PROV > $OUT.for_PROV && rm -f $OUT.chr*.for_PROV
  if [[ "$QC1" != *"--do-nothing"* ]]; then vQC --prefix $OUT.1st $QCJ --join-sample-qc $OUT.chr*.sample_qc; fi
  if [ -s $OUT.vqslod ]; then vQS $OUT.vqslod > $OUT.vqslod_cutoff; fi
  if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at STEP_1'; exit 1; fi
  echo >&2 $SLURM_JOB_NAME': STEP_1 completed '$(date)
fi

if [ -s $OUT.vqslod_cutoff ]; then
  if [ `grep filt-vqs- $OUT.vqslod_cutoff | wc -l` -gt 0 ]; then export QC1="`grep filt-vqs- $OUT.vqslod_cutoff | tr '\n' ' '` $QC1"; fi
fi

# Basic sample-wise quality control
if [ "$SPL_QC" == yes ]; then
  echo >&2 $SLURM_JOB_NAME': begin to do basic sample-wise quality control '$(date)
  echo $'#SeqID\tReason' > $OUT.sample_rm

  # Sample-wise QC Filters. 
  if [ "$AvDP_Cut" != 0 ]; then awk '($15!=-1)&&($15>'$SPL_MISS')' $OUT.1st.sample_qc |grep -v ^# |cut -f 1 |sed 's/$/\tMissingRate/' >> $OUT.sample_rm; fi
  if [ "$HeHo_Cut" != 0 ]; then awk '($16!=-1)&&($16>'$HeHo_Cut')' $OUT.1st.sample_qc |grep -v ^# |cut -f 1 |sed 's/$/\tHet\/Hom/'    >> $OUT.sample_rm; fi
  if [ "$TiTv_Cut" != 0 ]; then awk '($18!=-1)&&($18<'$TiTv_Cut')' $OUT.1st.sample_qc |grep -v ^# |cut -f 1 |sed 's/$/\tTi\/Tv/'      >> $OUT.sample_rm; fi
  if [ "$Conc_Cut" != 0 ]; then awk '($31!=-1)&&($31<'$Conc_Cut')' $OUT.1st.sample_qc |grep -v ^# |cut -f 1 |sed 's/$/\tConcordance/' >> $OUT.sample_rm; fi
  if [ "$AvGQ_Cut" != 0 ]; then awk '($32!=0) &&($34<'$AvGQ_Cut')' $OUT.1st.sample_qc |grep -v ^# |cut -f 1 |sed 's/$/\tmeanGQ/'      >> $OUT.sample_rm; fi
  if [ "$AvDP_Cut" != 0 ]; then awk '($33!=0) &&($35<'$AvDP_Cut')' $OUT.1st.sample_qc |grep -v ^# |cut -f 1 |sed 's/$/\tmeanDP/'      >> $OUT.sample_rm; fi

  if [ "$SEX_QC" == yes ]; then cat $OUT.1st.sex_problem >> $OUT.sample_rm; fi

  # do variant-wise quality control again with bad samples removed
  echo >&2 $SLURM_JOB_NAME': begin to do variant-wise quality control again with bad samples removed '$(date)
  my_func() { INP=$OUT.chr$1.vcf.gz SPL=$SPL PED=$PED \
              VAM=$VAM AN1=$AN1 AN2=$AN2 AN3=$AN3 AN4=$AN4 AN5=$AN5 KEEP_COMMON=$KEEP_COMMON \
              QC1="$RMS --rm-ind+=$OUT.sample_rm --log=$OUT.chr$1.qc.log.gz --nt=$QC_THREADS $QC1" \
              STEP1_ONLY=yes USE_TABIX=$USE_TABIX victor_by_chr; }
  export -f my_func
  parallel $PRL_OPT -a $CHF my_func
  cat $OUT.chr*.for_PROV > $OUT.for_PROV && rm -f $OUT.chr*.for_PROV
  if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at SPL_QC'; exit 1; fi
  echo >&2 $SLURM_JOB_NAME': SPL_QC/SEX_QC completed '$(date)
fi

if [ -s $OUT.sample_rm ]; then export RMS="$RMS --rm-ind+=$OUT.sample_rm"; fi

# Mendelian inconsistency and population stratification
if [ "$PED_QC" == yes ] || [ "$REL_QC" == yes ] || [ "$SPL_PC" == yes ]; then
  # prepare data for Mendelian inconsistency detection and principle component analysis
  echo >&2 $SLURM_JOB_NAME': begin to prepare data for Mendelian inconsistency detection and principle component analysis '$(date)
  command -v $PLINK19 >/dev/null 2>&1 || { echo >&2 $SLURM_JOB_NAME': !!! Error: PLINK 1.9 not found. Aborted at SPL_PC.'; exit 1; }
  export OTH_OPT="--rev-filt-MaxAF=0.001 --change-id --keep-unk --spl=$SPL --ped=$PED $RMS"
  # Do not use --filt-mac or --rev-filt-FdrAF. They inflate kinship coefficient, especially when sample size is small.
  vConvertVCF --id-delim : $OUT.chr*.qc.vcf.gz $OTH_OPT --add=yes --fam=$OUT.fam --no-mhc | bgzip -c > $OUT.data_a.vcf.gz
  tabix -f -p vcf $OUT.data_a.vcf.gz
  $PLINK19 --id-delim : --vcf $OUT.data_a.vcf.gz --keep $OUT.fam.to_keep --indiv-sort file $OUT.fam.to_keep --keep-allele-order --make-bed --out $OUT.data_a
  if [ `grep "Error: Duplicate ID" $OUT.data_a.log | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Duplicated ID in PED or SPL'; fi
  if [ `grep -i Error $OUT.data_a.log | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted before PED_QC/REL_QC/SPL_PC'; exit 1; fi
  mv $OUT.fam.to_repl $OUT.data_a.fam # restore pedigree structure and sex and affection status. The order of PID:IID should be the same.
  $PLINK19 --bfile $OUT.data_a --indep-pairphase 20000 2000 0.5                                --out $OUT.data_b
  if [ `cat $OUT.data_b.prune.in | wc -l` -gt 1000 ]; then
    $PLINK19 --bfile $OUT.data_a --extract $OUT.data_b.prune.in --keep-allele-order --make-bed --out $OUT.data_c
  else
    cp $OUT.data_a.bed $OUT.data_c.bed; cp $OUT.data_a.bim $OUT.data_c.bim; cp $OUT.data_a.fam $OUT.data_c.fam; 
  fi
  if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted before PED_QC/REL_QC/SPL_PC'; exit 1; fi

  # detect Mendelian inconsistency and cryptic relatedness by KING
  if [ "$PED_QC" == yes ] || [ "$REL_QC" == yes ]; then
    echo >&2 $SLURM_JOB_NAME': begin to detect cryptic relatedness and Mendelian inconsistency by KING '$(date)
    command -v $KING >/dev/null 2>&1 || { echo >&2 $SLURM_JOB_NAME': !!! Error: KING not found. Aborted at PED_QC.'; exit 1; }
    $KING -b $OUT.data_c.bed --kinship --related --degree 2 --prefix $OUT.data_c
    if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at PED_QC'; exit 1; fi
  fi

  # perform principle component analysis by PLINK
  if [ "$SPL_PC" == yes ]; then
    echo >&2 $SLURM_JOB_NAME': begin to perform principle component analysis by PLINK '$(date)
    $PLINK19 --bfile $OUT.data_c --mind 0.1 --pca --out $OUT.data_c
    vPC --spl=$SPL --eigenvec=$OUT.data_c.eigenvec --eigenval=$OUT.data_c.eigenval > $OUT.sample_pc
    if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at SPL_PC'; exit 1; fi
  fi
  
  echo >&2 $SLURM_JOB_NAME': PED_QC/REL_QC/SPL_PC(part_1) completed '$(date)
fi

# test the difference in #RV/sample between cases and controls, check relatedness
if [ "$SPL_QC" == yes ] || [ "$SPL_PC" == yes ] || [ "$PED_QC" == yes ] || [ "$REL_QC" == yes ]; then
  echo >&2 $SLURM_JOB_NAME': begin to test the difference in #RV/sample between cases and controls, check relatedness '$(date)
  export QCK="$RMS"
  if [ -f $OUT.data_c.kin ] && [ -f $OUT.data_c.kin0 ]; then export QCK="--king=$OUT.data_c $QCK"; fi
  if [ "$KEEP_REL" == yes ];                            then export QCK="--kin-cutoff=0.35355 $QCK"; fi
  if [ -s $OUT.sample_pc ]; then vQC --prefix $OUT.2nd --spl=$OUT.sample_pc --ped=$PED $QCK $QCJ --join-sample-qc $OUT.chr*.sample_qc;
  else                           vQC --prefix $OUT.2nd --spl=$SPL           --ped=$PED $QCK $QCJ --join-sample-qc $OUT.chr*.sample_qc; fi
  if [ -s $OUT.2nd.ped_errors ]; then 
    echo >&2 $SLURM_JOB_NAME': !!! Error: Found pedigree errors. Please check '$OUT.2nd.ped_errors', modify $PED and $SPL, then run PED_QC again.'
    echo >&2 $SLURM_JOB_NAME': !!! However, the inferred genetic correlation may not be accurate for distant relatives or when the pedigree has loops.'
    echo >&2 $SLURM_JOB_NAME': !!! If you are sure about the pedigree structure and want to continue, you can disable PED_QC.'
    echo >&2 $SLURM_JOB_NAME': !!! Aborted at PED_QC.'
    exit 1
  fi
  if [ -s $OUT.2nd.ped_warnings ]; then
    echo >&2 $SLURM_JOB_NAME':  !  Warning: Found pedigree warnings. Please check '$OUT.2nd.ped_warnings' for potential pedigree structure error.'
    echo >&2 $SLURM_JOB_NAME':  !  However, the inferred genetic correlation may not be accurate for distant relatives or when the pedigree has loops.'
  fi
  if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at the end of PED_QC/REL_QC/SPL_PC'; exit 1; fi
  echo >&2 $SLURM_JOB_NAME': PED_QC/REL_QC/SPL_PC(part_2) completed '$(date)
fi

if [ -s $OUT.2nd.rel_problem ]; then export RMS="$RMS --rm-ind+=$OUT.2nd.rel_problem"; fi

# Do QC again. This time add an HWE filter. Use it for array data only, where variants have higher allele frequencies. Not tested.
if [ "$HWTEST" == yes ] && [ -s "$OUT.sample_pc" ]; then
  echo >&2 $SLURM_JOB_NAME': begin to do quality control again with HWE test '$(date)
  vPC --spl=$SPL --pc=$OUT.sample_pc > $OUT.sample_hw
  my_func() { INP=$OUT.chr$1.vcf.gz SPL=$OUT.sample_hw PED=$PED \
              VAM=$VAM AN1=$AN1 AN2=$AN2 AN3=$AN3 AN4=$AN4 AN5=$AN5 KEEP_COMMON=$KEEP_COMMON \
              QC1="$RMS --rm-ind+=$OUT.sample_rm --log=$OUT.chr$1.qc.log.gz --nt=$QC_THREADS $QC1" \
              STEP1_ONLY=yes USE_TABIX=$USE_TABIX victor_by_chr; }
  export -f my_func
  parallel $PRL_OPT -a $CHF my_func
  cat $OUT.chr*.for_PROV > $OUT.for_PROV && rm -f $OUT.chr*.for_PROV
  if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at HWTEST'; exit 1; fi
  echo >&2 $SLURM_JOB_NAME': HWTEST completed '$(date)
fi

# do genotype imputation
export STEP2_INPUT=qc
if [ "$IMPUTE" == yes ]; then
  echo >&2 $SLURM_JOB_NAME': begin to do genotype imputation '$(date)
  if [ ! -s "$IM2.chr1.mrg.qc.vcf.gz" ]; then
    export OTH_OPT="--filt-mac=10 --rev-filt-FdrAF=0.01 --rev-filt-MaxAF=0.005 --change-id --keep-unk --spl=$SPL --ped=$PED $RMS"
    vConvertVCF $OUT.chr*.qc.vcf.gz $OTH_OPT --add=no | bgzip -c > $OUT.com.vcf.gz && tabix -f -p vcf $OUT.com.vcf.gz
    if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at IMPUTE'; exit 1; fi
    if [ "$AVF" != "" ]; then
      if [ "$GATK" == "" ]; then echo >&2 $SLURM_JOB_NAME': !!! Error: GATK not defined. Aborted at IMPUTE.'; exit 1; fi
      if [[ "$GATK" == *"/path/to/"* ]]; then echo >&2 $SLURM_JOB_NAME': !!! Error: GATK not defined. Aborted at IMPUTE.'; exit 1; fi
      export NT_BY_CPU=`echo $((NCPU-2>1?NCPU-2:1))`
      export NT_BY_MEM=`expr $MEM_TOTAL / 2`
      export NUM_THREADS=`echo $((NT_BY_CPU<NT_BY_MEM?NT_BY_CPU:NT_BY_MEM))`
      if [ "$NUM_THREADS" -lt 1 ]; then export NUM_THREADS=1; fi
      echo >&2 "$SLURM_JOB_NAME: calculated NT_BY_CPU=$NT_BY_CPU NT_BY_MEM=$NT_BY_MEM"
      $GATK -T CombineVariants --num_threads $NUM_THREADS \
            --genotypemergeoption UNSORTED \
            --variant:array $AVF \
            --variant:seq   $OUT.com.vcf.gz \
            --filteredrecordsmergetype KEEP_IF_ANY_UNFILTERED \
            -o $OUT.com.mrg.vcf.gz \
            &> $OUT.com.mrg.log
      if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at IMPUTE'; exit 1; fi
      echo >&2 "Now please do imputation for $OUT.com.mrg.vcf.gz and merge with sequencing data by slurm.impute2mrg"
      rm -f $PRFX*
      echo '# '$(date) > $JOB_LOG.stop
      exit 0
      ### submit $OUT.com.mrg.vcf.gz to an imputation server
    else
      echo >&2 "Now please do imputation for $OUT.com.vcf.gz and merge with sequencing data by slurm.impute2mrg"
      rm -f $PRFX*
      echo '# '$(date) > $JOB_LOG.stop
      exit 0
      ### submit $OUT.com.vcf.gz to an imputation server
    fi
  fi
  if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at IMPUTE'; exit 1; fi
  echo >&2 $SLURM_JOB_NAME': IMPUTE completed '$(date)
fi
if ls $OUT.chr*.mrg.qc.vcf.gz 1>/dev/null 2>&1; then export STEP2_INPUT=mrg.qc; fi

# Step 2: annotate functional consequence, fill in missing PROVEAN, and compute BayesDel scores
if [ "$STEP_2" == yes ]; then
  echo >&2 $SLURM_JOB_NAME': begin to annotate functional consequence, fill in missing PROVEAN, and compute BayesDel scores '$(date)

  # Compute PROVEAN
  if [ -s $OUT.for_PROV ] && [ "$PVN" == "" ] && [ ! -s $OUT.for_PROV.ann.gz ]; then
    command -v provean.sh >/dev/null 2>&1
    if [ $? -eq 0 ]; then
      NT_BY_CPU=`echo $((NCPU-2>1?NCPU-2:1))`
      NT_BY_MEM=`expr $MEM_TOTAL / 3`
      export NUM_THREADS=`echo $((NT_BY_CPU<NT_BY_MEM?NT_BY_CPU:NT_BY_MEM))`
      if [ "$NUM_THREADS" -lt 1 ]; then export NUM_THREADS=1; fi
      vPROV $OUT.for_PROV --nt=$NUM_THREADS > $OUT.for_PROV.ann
      if [ -s $OUT.for_PROV.ann ]; then
        bgzip -f $OUT.for_PROV.ann
        tabix -f -p vcf $OUT.for_PROV.ann.gz
      fi
      echo >&2 $SLURM_JOB_NAME': PROVEAN_annotation(STEP_2_part_1) completed '$(date)
    else
      cut -f 1 $OUT.for_PROV > $PRFX.provean.tmp && mv $PRFX.provean.tmp $OUT.for_PROV
      echo >&2 $SLURM_JOB_NAME': Please calculate PROVEAN for variants in $OUT.for_PROV at http://provean.jcvi.org/, save the condensed result file'
      echo >&2 $SLURM_JOB_NAME': as xxx.result.one.tsv, set PVN=xxx.result.one.tsv in "Main Parameters", and then do STEP_2 and beyond.'
      rm -f $PRFX*
      echo '# '$(date) > $JOB_LOG.stop
      exit 0
      ### see above
    fi
  fi
  if [ -s $OUT.for_PROV.ann.gz ] && [ "$PVN" == "" ]; then export PVN=$OUT.for_PROV.ann.gz; fi

  if [ "$PHA" == ShapeIt ] || [ "$PHA" == BEAGLE ]; then
    my_func() { INP=$OUT.chr$1.$STEP2_INPUT.vcf.gz PROV_FILL_MS=$PVN VAG="--log=$OUT.chr$1.$STEP2_INPUT.ann.log.gz $VAG" ADF=$ADF DEL=$DEL \
                PHASING=$PHA SPL=$SPL PED=$PED MAP=$MAP BGL=$BGL VAM=$VAM QC2=$QC2 NO_PERCH=yes USE_TABIX=$USE_TABIX victor_by_chr;
                rm $OUT.chr$1.$STEP2_INPUT.phased.mnp.ann.gz;
                rm $OUT.chr$1.$STEP2_INPUT.phased.mnp.vcf.gz;
                mv $OUT.chr$1.$STEP2_INPUT.phased.mnp.ann.del.gz $OUT.chr$1.$STEP2_INPUT.ann.del.gz; }
    export -f my_func
    parallel -j 1 -a $CHF my_func
  else
    my_func() { INP=$OUT.chr$1.$STEP2_INPUT.vcf.gz PROV_FILL_MS=$PVN VAG="--log=$OUT.chr$1.$STEP2_INPUT.ann.log.gz $VAG" ADF=$ADF DEL=$DEL \
                PHASING=no NO_PERCH=yes USE_TABIX=$USE_TABIX victor_by_chr;
                rm $OUT.chr$1.$STEP2_INPUT.ann.gz; }
    export -f my_func
    parallel $PRL_OPT -a $CHF my_func
  fi

  if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at STEP_2'; exit 1; fi
  echo >&2 $SLURM_JOB_NAME': STEP_2 completed '$(date)
fi

# Step 2.b: report incidental findings
if [ "$STEP2B" == yes ]; then
  echo >&2 $SLURM_JOB_NAME': begin to do variant-wise quality control again for incidental finding reports '$(date)
  export RELAXED_QC="--filt-vqs-snv=-inf --filt-vqs-indel=-inf --filt-miss-rate=1 --filt-miss-pv=0"
  export RELAXED_QC="$RELAXED_QC --filt-discord=0 --filt-hwe-pv=0 --filt-Mendelian=0 --filt-de-novo=0 --filt-hh=0"
  head -1 $SPL > $OUT.incidental.spl
  sed 1d $SPL | awk '$3="affected"' >> $OUT.incidental.spl
  my_func() { cp $OUT.chr$1.vcf.gz $OUT.if.chr$1.vcf.gz;
              INP=$OUT.if.chr$1.vcf.gz SPL=$OUT.incidental.spl PED=$PED \
              VAM=$VAM AN1=$AN1 AN2=$AN2 AN3=$AN3 AN4=$AN4 AN5=$AN5 KEEP_COMMON=$KEEP_COMMON \
              QC1="$RMS --log=$OUT.if.chr$1.qc.log.gz --nt=$QC_THREADS $RELAXED_QC" \
              STEP1_ONLY=yes USE_TABIX=$USE_TABIX victor_by_chr; }
  export -f my_func
  parallel $PRL_OPT -a $CHF my_func

  echo >&2 $SLURM_JOB_NAME': begin to annotate functional consequence again for incidental finding reports '$(date)
  my_func() { INP=$OUT.if.chr$1.qc.vcf.gz PROV_FILL_MS=$PVN VAG="--log=$OUT.if.chr$1.qc.ann.log.gz --prefer=panel_incidental $VAG" DEL=$DEL \
              PHASING=no NO_PERCH=yes USE_TABIX=$USE_TABIX victor_by_chr; }
  export -f my_func
  parallel $PRL_OPT -a $CHF my_func

  echo >&2 $SLURM_JOB_NAME': begin to search for incidental findings '$(date)
  my_func() { INP=$OUT.if.chr$1.qc.ann.del.gz SPL=$OUT.incidental.spl PED="" \
              AAA="$RMS $AAA --filt-MaxAF=0.05 --filt-FdrAF=0 --filt-del=-inf --detail --show-if" SEG="" FIN="" victor_by_chr; }
  export -f my_func
  parallel $PRL_OPT -a $CHF my_func

  echo >&2 $SLURM_JOB_NAME': begin to merge findings from different chromosomes '$(date)
  grep '#CHROM' `/bin/ls $OUT.if.chr*.perch.txt | head -1` > $OUT.incidental
  cat $OUT.if.chr*.perch.txt | grep -v '#CHROM' >> $OUT.incidental
  rm $OUT.if.chr*
  if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at STEP2B'; exit 1; fi

  echo >&2 $SLURM_JOB_NAME': STEP2B completed '$(date)
fi

# ----------------------------------------------------------------- parameters_section_2/2 -----------------------------------------------------------------

# PERCH files (each analysis has different Sample / Pedigree / GBA File with corresponding AAA2 / SEG2 parameters).
# If you have different $SPL,$PED between QC and PERCH analysis, change the $SPL2,$PED2 below. If you have more than one analysis, add SUP_I.
# If the files for QC and files for analysis are the same, you don't need to change anything.

for (( SUP_I = 1 ; SUP_I <= 1 ; SUP_I++ )); do

  if   [ "$SUP_I" == 1 ]; then
    export SPL2="$SPL"
    export PED2="$PED"
    export AAA2="$AAA"
    export SEG2="$SEG"
    export GBA=$GBA
    export SUP_N=""
  fi

  # PERCH Parameters. All arrays have the same number of items. Each column is a set of parameters for one analysis. You can add / remove / modify a column.
  export RUN_NAME=( combined       burden            detail                     collapse           varRank                   )
  export SPL_FILE=( "$SPL2"        "$SPL2"           "$SPL2"                    "$SPL2"            "$SPL2"                   )
  export PED_FILE=( "$PED2"        ""                ""                         ""                 "$PED2"                   )
  export VAAA_OPT=( "$AAA2"        "$AAA2 --out-mlp" "$AAA2 --detail --show-id" "$AAA2 --collapse" "$AAA2 --single"          )
  export VSEG_OPT=( "$SEG2"        ""                ""                         ""                 "$SEG2 --single"          )
  export VFIN_OPT=( "$FIN"         "$FIN"            "$FIN"                     "$FIN"             "$FIN --vc --prior=0.005" )
  
  # PERCH sub-analysis. All arrays have the same number of items. Each column is a set of parameters for one analysis. You can add / remove / modify a column.
  export SUB_NAME=( default  lof_only      dom_neg      )
  export SUB_PARS=( ""       "--lof-only"  "--dom-neg"  )

# -------------------------------------------------------------------- end_of_section2/2 --------------------------------------------------------------------

  # PERCH analysis
  for (( x = 0 ; x < ${#SUB_NAME[@]} ; x++ )); do
  
    # Step 3: conduct gene- or variant-based analyses
    if [ "$STEP_3" == yes ]; then
      echo >&2 $SLURM_JOB_NAME': begin to conduct PERCH analyses '$(date)
  
      for (( i = 0 ; i < ${#RUN_NAME[@]} ; i++ )); do
  
        export THIS_SPL="${SPL_FILE[$i]}"
        export THIS_PED="${PED_FILE[$i]}"
        export THIS_AAA="${VAAA_OPT[$i]} ${SUB_PARS[$x]}"
        export THIS_SEG="${VSEG_OPT[$i]} ${SUB_PARS[$x]}"
        export THIS_FIN="--biol=$GBA ${VFIN_OPT[$i]}"
  
        if [ -s "$OUT.sample_pc" ]; then
          vPC --spl=$THIS_SPL --pc=$OUT.sample_pc > $OUT.samples.${RUN_NAME[$i]}
          export THIS_SPL=$OUT.samples.${RUN_NAME[$i]}
        else
          cp $THIS_SPL $OUT.samples.${RUN_NAME[$i]}
        fi
        if [ -s "$THIS_PED" ]; then cp $THIS_PED $OUT.pedigrees.${RUN_NAME[$i]}; fi
  
        # set removed samples
        export THIS_AAA="$RMS $THIS_AAA"
        export THIS_SEG="$RMS $THIS_SEG"
  
        # do analysis with parallelism by chromosome
        my_func() { INP=$OUT.chr$1.$STEP2_INPUT.ann.del.gz SPL=$THIS_SPL PED=$THIS_PED AAA=$THIS_AAA SEG=$THIS_SEG FIN=$THIS_FIN PMT=$PMT victor_by_chr; }
        export -f my_func
        parallel $PRL_OPT -a $CHF my_func
  
        # merge results from all chromosomes into one file
        grep '#CHROM' `/bin/ls $OUT.chr*.perch.txt | head -1` > $OUT.results_${RUN_NAME[$i]}
        cat $OUT.chr*.perch.txt | grep -v '#CHROM' | sort -k 4,4 -r -g >> $OUT.results_${RUN_NAME[$i]}
        rm $OUT.*.perch.txt $OUT.*.perch.gz
      done
  
      if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at STEP_3'; exit 1; fi
      echo >&2 $SLURM_JOB_NAME': STEP_3 completed '$(date)
    fi
  
    # Step 4.a: conduct gene set analyses
    if [ "$STEP4A" == yes ]; then
      echo >&2 $SLURM_JOB_NAME': begin to conduct gene set analyses '$(date)
  
      if [ ! -s $OUT.results_detail ]; then echo >&2 $SLURM_JOB_NAME': !!! $OUT.results_detail not found. Aborted at STEP4A.'; exit 1; fi
  
      export NT_BY_CPU=`echo $((NCPU-2>1?NCPU-2:1))`
      export GENE_SETS=GeneSet_BF_p.gmt,GeneSet_hgnc_fam.gmt,GeneSet_bi_fam.gmt,GeneSet_MSigDB_lt50.gmt
      export PATHWAYS=GeneSet_hgnc_fam.gmt,GeneSet_bi_fam.gmt,GeneSet_MSigDB_lt50.gmt
      vGrp $OUT.chr*.$STEP2_INPUT.ann.del.gz --gene-set=$GENE_SETS --collapse=$OUT.results_detail --invo-gba-file=$GBA $GSA \
           --prefix $OUT.gsa.var --nt=$NT_BY_CPU
  
      for (( i = 0 ; i < ${#RUN_NAME[@]} ; i++ )); do
  
        if [ "${RUN_NAME[$i]}" == combined ]; then continue; fi
        if [ "${RUN_NAME[$i]}" == varRank ]; then continue; fi
        if [ "${RUN_NAME[$i]}" == detail ]; then continue; fi
  
        export THIS_SPL="${SPL_FILE[$i]}"
        export THIS_PED="${PED_FILE[$i]}"
        export THIS_AAA="${VAAA_OPT[$i]} ${SUB_PARS[$x]}"
        export THIS_SEG="${VSEG_OPT[$i]} ${SUB_PARS[$x]}"
        export THIS_FIN="--biol=$GBA ${VFIN_OPT[$i]} --per-gene=$OUT.results_${RUN_NAME[$i]} --gene-set=$PATHWAYS --show-genes"
        export THIS_RES="$OUT.gsa.results_${RUN_NAME[$i]}"
  
        if [ -s "$OUT.sample_pc" ]; then
          vPC --spl=$THIS_SPL --pc=$OUT.sample_pc > $OUT.samples.${RUN_NAME[$i]}
          export THIS_SPL=$OUT.samples.${RUN_NAME[$i]}
        else
          cp $THIS_SPL $OUT.samples.${RUN_NAME[$i]}
        fi
        if [ -s "$THIS_PED" ]; then cp $THIS_PED $OUT.pedigrees.${RUN_NAME[$i]}; fi
  
        # set removed samples
        export THIS_AAA="$RMS --spl=$THIS_SPL $THIS_AAA"
        export THIS_SEG="$RMS --ped=$THIS_PED $THIS_SEG"
  
        # write code
        rm -f $OUT.gsa.options
        for (( j = 1 ; j <= $NT_BY_CPU ; j++ )); do
          echo "$OUT.gsa.var.$j $THIS_AAA"$'\t'"$THIS_FIN"$'\t'"$THIS_RES.$j" >> $OUT.gsa.options
        done
        my_func() { vAAA2 $1 --gtp=$OUT.chr@.$STEP2_INPUT.vcf.gz --group=GeneSet | vFIN $2 --group=GeneSet > $3; }
        export -f my_func
        parallel -a $OUT.gsa.options --colsep '\t' my_func
        grep '#CHROM' $THIS_RES.1 > $THIS_RES
        grep -v '#CHROM' $THIS_RES.* | sort -k 4,5 -r -g >> $THIS_RES
        rm -f $OUT.gsa.options $THIS_RES.*
      done
  
      head -10000 $OUT.gsa.var.1 | grep ^# > $OUT.gsa.var
      cat $OUT.gsa.var.* | grep -v ^# >> $OUT.gsa.var
      rm $OUT.gsa.var.*
      gzip $OUT.gsa.var
  
      if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at STEP4A'; exit 1; fi
      echo >&2 $SLURM_JOB_NAME': STEP4A completed '$(date)
    fi
  
    # Step 4.b: PERCH gene- or variant-based analysis after removing samples who carry variants in known high-penetrance genes
    if [ "$STEP4B" == yes ]; then
  
      echo >&2 $SLURM_JOB_NAME': begin to conduct PERCH analyses after removing samples who carry variants in known high-penetrance genes '$(date)
  
      if [ ! -s $OUT.incidental ]; then echo >&2 $SLURM_JOB_NAME': !!! $OUT.incidental not found. Aborted at STEP4B.'; exit 1; fi
  
      rm -f $OUT.sample_rm_byHPG
      if [ "$HPG" != "" ]; then
        IFS=, read -r -a GENES <<< "$HPG"
        for GENE in ${GENES[@]}; do
          grep $'\t'"$GENE"$'\t' $OUT.incidental | awk '{print $8,$5}' | tr = '\t' | tr ' ' '\t' | cut -f 1,4 >> $OUT.sample_rm_byHPG
        done
      else
        sed 1d $OUT.incidental | awk '{print $8,$5}' | tr = '\t' | tr ' ' '\t' | cut -f 1,4 >> $OUT.sample_rm_byHPG
      fi
  
      if [ -s $OUT.sample_rm_byHPG ]; then
        for (( i = 0 ; i < ${#RUN_NAME[@]} ; i++ )); do
  
          export THIS_SPL="${SPL_FILE[$i]}"
          export THIS_PED="${PED_FILE[$i]}"
          export THIS_AAA="${VAAA_OPT[$i]} ${SUB_PARS[$x]}"
          export THIS_SEG="${VSEG_OPT[$i]} ${SUB_PARS[$x]}"
          export THIS_FIN="--biol=$GBA ${VFIN_OPT[$i]}"
  
          if [ -s "$OUT.sample_pc" ]; then
            vPC --spl=$THIS_SPL --pc=$OUT.sample_pc > $OUT.samples.${RUN_NAME[$i]}
            export THIS_SPL=$OUT.samples.${RUN_NAME[$i]}
          else
            cp $THIS_SPL $OUT.samples.${RUN_NAME[$i]}
          fi
          if [ -s "$THIS_PED" ]; then cp $THIS_PED $OUT.pedigrees.${RUN_NAME[$i]}; fi
  
          # set removed samples
          export THIS_AAA="$RMS --rm-ind+=$OUT.sample_rm_byHPG $THIS_AAA"
          export THIS_SEG="$RMS --rm-ind+=$OUT.sample_rm_byHPG $THIS_SEG"
  
          # do analysis with parallelism by chromosome
          my_func() { INP=$OUT.chr$1.$STEP2_INPUT.ann.del.gz SPL=$THIS_SPL PED=$THIS_PED AAA=$THIS_AAA SEG=$THIS_SEG FIN=$THIS_FIN PMT=$PMT victor_by_chr; }
          export -f my_func
          parallel $PRL_OPT -a $CHF my_func
  
          # merge results from all chromosomes into one file
          grep '#CHROM' `/bin/ls $OUT.chr*.perch.txt | head -1` > $OUT.rmHPG.${RUN_NAME[$i]}
          cat $OUT.chr*.perch.txt | grep -v '#CHROM' | sort -k 4,4 -r -g >> $OUT.rmHPG.${RUN_NAME[$i]}
          rm $OUT.*.perch.txt $OUT.*.perch.gz
        done
      fi
  
      if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at STEP4B'; exit 1; fi
      echo >&2 $SLURM_JOB_NAME': STEP4B completed '$(date)
    fi
  
    # Step 4.c: PERCH with ExAC_nonTCGA (not recommended)
    if [ "$STEP4C" == yes ]; then
  
      echo >&2 $SLURM_JOB_NAME': begin to conduct PERCH analyses with ExAC_nonTCGA '$(date)
  
      cat $CHF | grep -v Y | grep -v M > $OUT.ExAC.chr
  
      for (( i = 0 ; i < ${#RUN_NAME[@]} ; i++ )); do
  
        if [ "${RUN_NAME[$i]}" == varRank ]; then continue; fi
        if [ "${RUN_NAME[$i]}" == detail ]; then export DO_EXAC_LOG=yes; fi
  
        export THIS_SPL="${SPL_FILE[$i]}"
        export THIS_PED="${PED_FILE[$i]}"
        export THIS_AAA="${VAAA_OPT[$i]} ${SUB_PARS[$x]}"
        export THIS_SEG="${VSEG_OPT[$i]} ${SUB_PARS[$x]}"
        export THIS_FIN="--biol=$GBA ${VFIN_OPT[$i]}"
  
        if [ -s "$OUT.sample_pc" ]; then
          vPC --spl=$THIS_SPL --pc=$OUT.sample_pc > $OUT.samples.${RUN_NAME[$i]}
          export THIS_SPL=$OUT.samples.${RUN_NAME[$i]}
        else
          cp $THIS_SPL $OUT.samples.${RUN_NAME[$i]}
        fi
        if [ -s "$THIS_PED" ]; then cp $THIS_PED $OUT.pedigrees.${RUN_NAME[$i]}; fi
  
        # set removed samples
        export THIS_AAA="$RMS $THIS_AAA --exclude=DacExcludable.bed.gz,DukeExcludable.bed.gz $AWX"
        export THIS_SEG="$RMS $THIS_SEG --exclude=DacExcludable.bed.gz,DukeExcludable.bed.gz"
  
        # do analysis with parallelism by chromosome
        if [ "$DO_EXAC_LOG" == yes ]; then
          my_func() { INP=$OUT.chr$1.$STEP2_INPUT.ann.del.gz SPL=$THIS_SPL PED=$THIS_PED \
                      AAA="$THIS_AAA --xct-log=$OUT.chr$1.ExAC.log --xct-pfx=$EFP.chr$1,$OUT.chr$1,$COV.chr$1" \
                      SEG=$THIS_SEG FIN=$THIS_FIN PMT=$PMT victor_by_chr; }
        else
          my_func() { INP=$OUT.chr$1.$STEP2_INPUT.ann.del.gz SPL=$THIS_SPL PED=$THIS_PED \
                      AAA="$THIS_AAA --xct-pfx=$EFP.chr$1,$OUT.chr$1,$COV.chr$1" \
                      SEG=$THIS_SEG FIN=$THIS_FIN PMT=$PMT victor_by_chr; }
        fi
        export -f my_func
        parallel $PRL_OPT -a $OUT.ExAC.chr my_func
  
        # merge results from all chromosomes into one file
        grep '#CHROM' `/bin/ls $OUT.chr*.perch.txt | head -1` > $OUT.ExAC.results_${RUN_NAME[$i]}
        cat $OUT.chr*.perch.txt | grep -v '#CHROM' | sort -k 4,4 -r -g >> $OUT.ExAC.results_${RUN_NAME[$i]}
        rm $OUT.*.perch.txt $OUT.*.perch.gz
        if [ "$DO_EXAC_LOG" == yes ]; then
          echo "Gene Variant Log" | tr ' ' '\t' > $OUT.ExAC.log
          cat $OUT.chr*.ExAC.log >> $OUT.ExAC.log
          rm $OUT.chr*.ExAC.log
        fi
  
      done
      if [ `grep -i "$ERROR_TEXT" $JOB_LOG.stderr | wc -l` -gt 0 ]; then echo >&2 $SLURM_JOB_NAME': !!! Aborted at STEP4C'; exit 1; fi
  
      echo >&2 $SLURM_JOB_NAME': STEP4C completed '$(date)
    fi
    
    # significant results
    for F in *.results_burden; do
      if [[ $F == *ExAC* ]]; then continue; fi
      NTESTS=`sed 1d $F | wc -l`
      CUTOFF=`echo "-l(0.05/$NTESTS)/l(10)" | bc -l`
      NSIGF=`sed 1d $F | awk '($4>'$CUTOFF')' | wc -l`
      if [ "$NSIGF" -gt 0 ]; then
        echo '### '$JOB_LOG.results${SUP_N}/${SUB_NAME[$x]}/$F >> $JOB_LOG.sig
        head -1 $F >> $JOB_LOG.sig
        sed 1d $F | awk '($4>'$CUTOFF')' >> $JOB_LOG.sig
        echo -------------------------------------------------------------------------------- >> $JOB_LOG.sig
      fi
    done
    
    # copy results                                                                                                                                                                                           
    mkdir -p $JOB_LOG.results${SUP_N}/${SUB_NAME[$x]}/
    if [ -f $OUT.2nd.rel_problem ]; then      cp $OUT.2nd.rel_problem $JOB_LOG.results${SUP_N}/${SUB_NAME[$x]}/; fi
    if ls $OUT.sample_*    1>/dev/null 2>&1; then cp $OUT.sample_*    $JOB_LOG.results${SUP_N}/${SUB_NAME[$x]}/; fi
    if ls $OUT.samples.*   1>/dev/null 2>&1; then mv $OUT.samples.*   $JOB_LOG.results${SUP_N}/${SUB_NAME[$x]}/; fi
    if ls $OUT.pedigrees.* 1>/dev/null 2>&1; then mv $OUT.pedigrees.* $JOB_LOG.results${SUP_N}/${SUB_NAME[$x]}/; fi
    if ls $OUT.results_*   1>/dev/null 2>&1; then mv $OUT.results_*   $JOB_LOG.results${SUP_N}/${SUB_NAME[$x]}/; fi
    if ls $OUT.gsa.*       1>/dev/null 2>&1; then mv $OUT.gsa.*       $JOB_LOG.results${SUP_N}/${SUB_NAME[$x]}/; fi
    if ls $OUT.rmHPG.*     1>/dev/null 2>&1; then mv $OUT.rmHPG.*     $JOB_LOG.results${SUP_N}/${SUB_NAME[$x]}/; fi
    if ls $OUT.ExAC.*      1>/dev/null 2>&1; then mv $OUT.ExAC.*      $JOB_LOG.results${SUP_N}/${SUB_NAME[$x]}/; fi
    
  done
  
done

# All completed.
rm -f $PRFX*
echo >&2 $SLURM_JOB_NAME': All completed '$(date)
echo '# '$(date) > $JOB_LOG.stop
